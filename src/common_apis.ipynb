{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export LANG='ko_KR.UTF-8'\r\n"
     ]
    }
   ],
   "source": [
    "!export | grep $LANG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Copyright (C) 2018.02.09 kyung seok jeong <humanist96@koscom.co.kr>\n",
    "from __future__ import absolute_import, unicode_literals\n",
    "from natto import MeCab\n",
    "import pandas as pd\n",
    "import collections\n",
    "import re\n",
    "import datrie\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stopword(fpath):\n",
    "    \"\"\"\n",
    "    Return the trie object of stopword dictionary\n",
    "    - input : stopword file path\n",
    "    - output : trie instance\n",
    "    \"\"\"\n",
    "    _escape_pattern = ['\\n']\n",
    "    \n",
    "    try:\n",
    "        trie=datrie.Trie(ranges=[(u'\\u0000', u'\\uFFFF')])\n",
    "\n",
    "        with open(fpath, \"rb\", 0) as f:\n",
    "            for word in f.readlines():\n",
    "                word=word.decode(\"utf-8\").rstrip()           \n",
    "                trie[word] = True\n",
    "    except Exception as e:\n",
    "        print(\"[load_storpwod] messages of error :\", e)\n",
    "        return ''\n",
    "    \n",
    "    return trie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_stopword(morpheme, trie):\n",
    "    \"\"\"\n",
    "    Returns the presence or absence of stopword in stopword dictionary.\n",
    "    - input : morpheme string, trie instance\n",
    "    - output : boolean (Ture, False)\n",
    "    \"\"\"\n",
    "    if morpheme in trie:\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<natto.mecab.MeCab model=<cdata 'mecab_model_t *' 0x22ffff0>, tagger=<cdata 'mecab_t *' 0x23023e0>, lattice=<cdata 'mecab_lattice_t *' 0x22d8d30>, libpath=\"/usr/local/lib/libmecab.so\", options={'node_format': '%m,%f[0],%f[1],%f[2],%f[3],%f[4],%f[5],%f[6],%f[7]\\\\n', 'nbest': 1}, dicts=[<natto.dictionary.DictionaryInfo dictionary=<cdata 'mecab_dictionary_info_t *' 0x2320a30>, filepath=\"/usr/local/lib/mecab/dic/mecab-ko-dic/sys.dic\", charset=UTF-8, type=0>], version=0.996/ko-0.9.2>\n",
      "   surface     tag meaning_class final_consonant reading      type first_tag  \\\n",
      "0       어떤      MM           ~명사               T      어떤                       \n",
      "1        가     JKS                             F       가                       \n",
      "2     대한민국     NNP            지명               T    대한민국  Compound             \n",
      "3      형태소     NNG                             F     형태소  Compound             \n",
      "4      분석기     NNG                             F     분석기  Compound             \n",
      "5        는      JX                             T       는                       \n",
      "6       한글     NNG                             T      한글                       \n",
      "7        을     JKO                             T       을                       \n",
      "8        잘     MAG                             T       잘                       \n",
      "9       분석     NNG                             T      분석                       \n",
      "10      할지  XSV+EC                             F      할지   Inflect       XSV   \n",
      "11       물      VV                             T       물   Inflect        VV   \n",
      "12       었      EP                             T       었                       \n",
      "13       다      EF                             F       다                       \n",
      "14       ?      SF                                                             \n",
      "\n",
      "   final_tag         expression  \n",
      "0                                \n",
      "1                                \n",
      "2             대한/NNG/*+민국/NNG/*  \n",
      "3              형태/NNG/*+소/NNG/*  \n",
      "4              분석/NNG/*+기/NNG/*  \n",
      "5                                \n",
      "6                                \n",
      "7                                \n",
      "8                                \n",
      "9                                \n",
      "10        EC    하/XSV/*+ᆯ지/EC/*  \n",
      "11        VV             묻/VV/*  \n",
      "12                               \n",
      "13                               \n",
      "14                               \n",
      "Help on function run_ma in module __main__:\n",
      "\n",
      "run_ma(text, stop_path='', nBest=1)\n",
      "    Returns the dataframe of all Information of morpheme analyzer.\n",
      "    - input : string, {stopword file path}, {nbest number}\n",
      "    - output : dataframe\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def run_ma(text, stop_path='', nBest=1):\n",
    "    \"\"\"\n",
    "    Returns the dataframe of all Information of morpheme analyzer.\n",
    "    - input : string, {stopword file path}, {nbest number}\n",
    "    - output : dataframe\n",
    "    \"\"\"\n",
    "    options=r'-F%m,%f[0],%f[1],%f[2],%f[3],%f[4],%f[5],%f[6],%f[7]\\n'\n",
    "    options+=\" -N\"+str(nBest)\n",
    "    \n",
    "    stopword_flag=False\n",
    "    \n",
    "    if stop_path != '':\n",
    "        stopword_flag=True\n",
    "    try:   \n",
    "        _me=MeCab(options)\n",
    "\n",
    "        _df = pd.DataFrame(None, columns=['surface', 'tag', 'meaning_class', 'final_consonant', \n",
    "                                         'reading', 'type', 'first_tag', 'final_tag','expression'])\n",
    "\n",
    "        if stopword_flag:\n",
    "            trie=load_stopword(stop_path)\n",
    "\n",
    "        i=0\n",
    "        for term_str in str(_me.parse(text)).split('\\n'):\n",
    "            term_list = re.split(',', term_str)\n",
    "\n",
    "            if stopword_flag == True and is_stopword(term_list[0], trie):\n",
    "                continue\n",
    "            if len(term_list) < 2:\n",
    "                continue\n",
    "\n",
    "            _df.loc[i]=term_list   \n",
    "            i+=1\n",
    "    except Exception as e:\n",
    "        print(\"[run_ma] messages of error : \", e)\n",
    "        \n",
    "    return _me, _df\n",
    "\n",
    "me, df=run_ma(\"어떤기자가 대한민국 형태소분석기는 한글을 잘 분석할지 물었다?\", \"./stopword.txt\")\n",
    "print(me)\n",
    "print(df)\n",
    "help(run_ma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   surface     tag meaning_class final_consonant reading      type first_tag  \\\n",
      "0       어떤      MM           ~명사               T      어떤                       \n",
      "1        가     JKS                             F       가                       \n",
      "2     대한민국     NNP            지명               T    대한민국  Compound             \n",
      "3      형태소     NNG                             F     형태소  Compound             \n",
      "4      분석기     NNG                             F     분석기  Compound             \n",
      "5        는      JX                             T       는                       \n",
      "6       한글     NNG                             T      한글                       \n",
      "7        을     JKO                             T       을                       \n",
      "8        잘     MAG                             T       잘                       \n",
      "9       분석     NNG                             T      분석                       \n",
      "10      할지  XSV+EC                             F      할지   Inflect       XSV   \n",
      "11       물      VV                             T       물   Inflect        VV   \n",
      "12       었      EP                             T       었                       \n",
      "13       다      EF                             F       다                       \n",
      "14       ?      SF                                                             \n",
      "\n",
      "   final_tag         expression  \n",
      "0                                \n",
      "1                                \n",
      "2             대한/NNG/*+민국/NNG/*  \n",
      "3              형태/NNG/*+소/NNG/*  \n",
      "4              분석/NNG/*+기/NNG/*  \n",
      "5                                \n",
      "6                                \n",
      "7                                \n",
      "8                                \n",
      "9                                \n",
      "10        EC    하/XSV/*+ᆯ지/EC/*  \n",
      "11        VV             묻/VV/*  \n",
      "12                               \n",
      "13                               \n",
      "14                               \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'어떤/MM 가/JKS 대한/NNG 민국/NNG 형태/NNG 소/NNG 분석/NNG 기/NNG 는/JX 한글/NNG 을/JKO 잘/MAG 분석/NNG 하/XSV ᆯ지/EC 묻/VV 었/EP 다/EF ?/SF\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df)\n",
    "\n",
    "def get_all_morph(df):\n",
    "    \"\"\"\n",
    "    Returns all morphemes and Part-of-Speech.\n",
    "    - input : dataframe\n",
    "    - output : string\n",
    "    \"\"\"\n",
    "    ret=''\n",
    "    for index, row in df.iterrows():      \n",
    "        if row['type'] == 'Inflect' or row['type'] == 'Compound':\n",
    "            tag=row['expression']\n",
    "            ret+=tag.replace('+',' ').replace(\"/*\", '')+\" \"\n",
    "        else:\n",
    "            tag=row['tag']\n",
    "            ret+=row['surface']+\"/\"+tag+\" \"        \n",
    "    ret=ret.rstrip()\n",
    "    ret=ret+\"\\n\"\n",
    "    \n",
    "    return(ret)\n",
    "\n",
    "get_all_morph(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   surface     tag meaning_class final_consonant reading      type first_tag  \\\n",
      "0       어떤      MM           ~명사               T      어떤                       \n",
      "1        가     JKS                             F       가                       \n",
      "2     대한민국     NNP            지명               T    대한민국  Compound             \n",
      "3      형태소     NNG                             F     형태소  Compound             \n",
      "4      분석기     NNG                             F     분석기  Compound             \n",
      "5        는      JX                             T       는                       \n",
      "6       한글     NNG                             T      한글                       \n",
      "7        을     JKO                             T       을                       \n",
      "8        잘     MAG                             T       잘                       \n",
      "9       분석     NNG                             T      분석                       \n",
      "10      할지  XSV+EC                             F      할지   Inflect       XSV   \n",
      "11       물      VV                             T       물   Inflect        VV   \n",
      "12       었      EP                             T       었                       \n",
      "13       다      EF                             F       다                       \n",
      "14       ?      SF                                                             \n",
      "\n",
      "   final_tag         expression  \n",
      "0                                \n",
      "1                                \n",
      "2             대한/NNG/*+민국/NNG/*  \n",
      "3              형태/NNG/*+소/NNG/*  \n",
      "4              분석/NNG/*+기/NNG/*  \n",
      "5                                \n",
      "6                                \n",
      "7                                \n",
      "8                                \n",
      "9                                \n",
      "10        EC    하/XSV/*+ᆯ지/EC/*  \n",
      "11        VV             묻/VV/*  \n",
      "12                               \n",
      "13                               \n",
      "14                               \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'대한민국/NNP 형태소/NNG 분석기/NNG 한글/NNG 분석/NNG\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df)\n",
    "\n",
    "def get_noun_morph(df, option='N'):\n",
    "    \"\"\"\n",
    "    Returns noun morphemes and Part-of-Speech.\n",
    "    - input : dataframe, {option : compound noun decomposition flag, default : N}\n",
    "    - output : string\n",
    "    \"\"\"\n",
    "    _noun_type = ['NNG', 'NNP']\n",
    "    ret=''\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        if row['tag'] in _noun_type:\n",
    "            if row['type'] == 'Compound' and option != 'N':\n",
    "                tag=row['expression']\n",
    "                ret+=tag.replace('+',' ').replace(\"/*\", '')+\" \"\n",
    "            else:\n",
    "                ret+=row['surface']+\"/\"+row['tag']+\" \" \n",
    "    ret=ret.rstrip()\n",
    "    ret=ret+\"\\n\"\n",
    "    \n",
    "    return(ret)\n",
    "\n",
    "get_noun_morph(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('분석', 1), ('형태소', 1), ('한글', 1), ('대한민국', 1), ('분석기', 1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_noun_term_freq(df, option='N'):\n",
    "    \"\"\"\n",
    "    Returns noun morphemes and freqeuncy\n",
    "    - input : dataframe, {option : compound noun decomposition flag, default : N}\n",
    "    - output : list of tuples(morpheme, frequency)\n",
    "    \"\"\"\n",
    "    _noun_type = ['NNG', 'NNP']\n",
    "    _terms = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        if row['tag'] in _noun_type:\n",
    "            if row['type'] == 'Compound' and option != 'N':\n",
    "                tag=row['expression']\n",
    "                _terms.extend(re.split(' ', tag.replace('+',' ').replace(\"/*\", '')))\n",
    "            else:\n",
    "                _terms.append(row['surface'])\n",
    "                \n",
    "    return sorted(collections.Counter(_terms).items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "get_noun_term_freq(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
