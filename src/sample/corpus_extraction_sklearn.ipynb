{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<natto.mecab.MeCab model=<cdata 'mecab_model_t *' 0x560337dbf420>, tagger=<cdata 'mecab_t *' 0x560337e6aee0>, lattice=<cdata 'mecab_lattice_t *' 0x560337692570>, libpath=\"/usr/local/lib/libmecab.so\", options={}, dicts=[<natto.dictionary.DictionaryInfo dictionary=<cdata 'mecab_dictionary_info_t *' 0x560337dbbc20>, filepath=\"/usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ko-dic/sys.dic\", charset=UTF-8, type=0>], version=0.996>\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from natto import MeCab\n",
    "\n",
    "\n",
    "_morpheme_type = ['NNG', 'NNP']\n",
    "_escape_pattern = ['\\n']\n",
    "_nm = MeCab()\n",
    "\n",
    "print(_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['한글']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def filter_by_type(text):\n",
    "    terms = []\n",
    "    for term_info in str(_nm.parse(text)).split('\\n'):\n",
    "        _term_info = term_info.split('\\t')\n",
    "        if len(_term_info) < 2:\n",
    "            continue\n",
    "        surface = _term_info[0]\n",
    "        analysis = _term_info[1].split(',')\n",
    "        if analysis[0] in _morpheme_type:\n",
    "            terms.append(surface)\n",
    "    return terms\n",
    "\n",
    "\n",
    "print(filter_by_type('한글좀잘잘라줄래말래?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['애플 중국 삼성전자 혁신', '중국 업체 추격 생각 하드웨어 중심 사고 탈피 시급', '서울 연합뉴스 새롬 기자 내년 삼성전자 스마트폰 출하량 역 성장 전망 한국 경제 성장 축 휴대폰 부문 세계 시장 주도 우려', '프리미엄 제품군 애플 경쟁 가열 중저가 제품군 중국 업체 파상 공세 입지 탓', '삼성전자 애플 화웨이 이미지', '스마트폰 시장 애플 진영 안팎 점유 유지 동안 삼성전자 나머지 업체 안드로이드 진영 경쟁 형국 삼성전자 당장 직면 위기 중국 업체 도전', '중국 업체 애플 삼성 스마트폰 카피 비용 폰 전략 최근 수년 급성장', '분기 기준 세계 스마트폰 시장 중국 차지 애플 제외 중국 업체 오포 화웨이 비보 샤오미 독식 삼성 점유 기록', '인도 시장 삼성전자 분기 점유 유지 샤오미 나머지 비보 오포 노보 중국 업체', '샤오미 최근 삼성전자 인도 법인 모바일 부문 판매 담당 임원 판매 책임자 영입 인도 시장 공략 박차', '삼성 빅스비', '전문가 시장 조사 기관 전망 실제 실적 전제 모방 기반 중국 업체 추격 생각 삼성전자 미래 전략 때 제언', '이병태 카 이스트 경영 대학 교수 프리미엄 제품 삼성전자 기술력 디자인 측면 차별 유지 중저가 시장 규모 경제 측면 대책 프리미엄 폰 사양 폰 채택 차별 지적', '교수 애플 아이폰 안면 인식 기능 소비자 호평 혁신 영역 삼성전자 혁신 제품 글로벌 시장 점유 확대 계기 말', '삼성 아프리카 포럼 자료 사진', '삼성전자 글로벌 전략 동남 아시아 아프리카 신흥 시장 위주 재편 하드웨어 위주 사고 사물 인터넷 소프트웨어 분야 신경 제언', '양현미 서울대 수리 과학부 교수 세계 이동 통신 사업자 연합회 최고 전략 책임자 중국 업체 인적 물 자원 고려 때 전망 예측 미래 앞 성장 가능 동남아 아프리카 시장 제품 전략 필요 말', '미국 유럽 포화 시장 집중 특화 현지 마케팅 유통 전략 신흥 시장 선점 때 지적', '교수 하드웨어 기기 스마트폰 차별 가능 성장 분야 삼성전자 삼성전자 조직 내부 스마트폰 가전 분야 공동 시너지 노력 강조']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_corpus2(data_path):\n",
    "    _corpus = []\n",
    "    fp = open(data_path, 'r')\n",
    "    for line in fp.readlines():\n",
    "        if line not in _escape_pattern:\n",
    "            terms = filter_by_type(line)\n",
    "            _corpus.append(' '.join(terms))\n",
    "    return _corpus\n",
    "\n",
    "\n",
    "print(generate_corpus2('news.txt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sample.txt'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8fda4140669f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_corpus2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sample.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0m_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mword_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-1f539c5c1c1a>\u001b[0m in \u001b[0;36mgenerate_corpus2\u001b[0;34m(data_path)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_corpus2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0m_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_escape_pattern\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sample.txt'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "\n",
    "corpus = generate_corpus2('./news.txt')\n",
    "_cv = CountVectorizer()\n",
    "word_matrix = _cv.fit_transform(corpus)\n",
    "\n",
    "index = 0\n",
    "for word_vector in word_matrix.toarray():\n",
    "    print('[', corpus[index], '] : \\n', word_vector)\n",
    "    index += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
